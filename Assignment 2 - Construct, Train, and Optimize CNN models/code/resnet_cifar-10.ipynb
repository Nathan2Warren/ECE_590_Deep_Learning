{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet CIFAR-10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** \n",
    "\n",
    "(4 pts) Implement the ResNet-20 architecture by following Section 4.2 of the ResNet paper [3]. This lab is designed to have you learn how to implement a DNN model yourself. DO NOT borrow any code from online resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Import pytorch dependencies\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "class Block_Regular(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, size):\n",
    "        super(Block_Regular, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.size = size\n",
    "        \n",
    "        # 1st conv: /2 downsamples the image resolution, 3x3\n",
    "        ### in = [16 x 32 x 32] \n",
    "        ### out = [16 x 32, 32]\n",
    "        self.conv1 = nn.Conv2d(self.in_channels, self.out_channels, 3, stride = 1, padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(self.out_channels)\n",
    "        \n",
    "        # 2nd conv of block, 3x3\n",
    "        ### in = [16 x 32 x 32]\n",
    "        ### out = [16 x 32 x 32]\n",
    "        self.conv2 = nn.Conv2d(self.in_channels, self.out_channels, 3, stride = 1, padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(self.out_channels)\n",
    "\n",
    "    def swish(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.swish(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = self.swish(torch.add(out, x))\n",
    "        return out\n",
    "        \n",
    "        \n",
    "class Block_Identity(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, size):\n",
    "        super(Block_Identity, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.size =size \n",
    "        \n",
    "        # 1st block: /2 downsamples the image resolution, 3x3\n",
    "        ### in = [16 x 32 x 32] \n",
    "        ### out = [32 x 16, 16]\n",
    "        self.conv3 = nn.Conv2d(self.in_channels, self.out_channels, 3, stride = 2, padding = 1)\n",
    "        self.bn3 = nn.BatchNorm2d(self.out_channels)\n",
    "        \n",
    "        # 2nd layer of block, 3x3\n",
    "        ### in = [32 x 16 x 16]\n",
    "        ### out = [32 x 16 x 16]\n",
    "        self.conv4 = nn.Conv2d(self.out_channels, self.out_channels, 3, padding = 1)\n",
    "        self.bn4 = nn.BatchNorm2d(self.out_channels)\n",
    "        \n",
    "        # Identity block: /2 downsamples the image resolution, 1x1 \n",
    "        ### in = [16 x 32 x 32] \n",
    "        ### out = [32 x 16, 16]\n",
    "        self.conv_down = nn.Conv2d(self.in_channels, self.out_channels, 1, stride = 2)\n",
    "        self.bn_down = nn.BatchNorm2d(self.out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.swish(self.bn3(self.conv3(x)))\n",
    "        out = self.bn4(self.conv4(out))\n",
    "        out2 = self.bn_down(self.conv_down(x))\n",
    "        return self.swish(torch.add(out, out2))\n",
    "    \n",
    "    def swish(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "# Create the neural network module: ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "    \n",
    "        # First megablock which does not change the size or number of channels\n",
    "        self.b1 = Block_Regular(16, 16, 32)\n",
    "        self.b2 = Block_Regular(16, 16, 32)\n",
    "        self.b3 = Block_Regular(16, 16, 32)\n",
    "\n",
    "        # Second megablock which takes in 16 channels and outputs 32 channels, H/W reduced 32 --> 16\n",
    "        self.b4 = Block_Identity(16, 32, 32)\n",
    "        self.b5 = Block_Regular(32, 32, 16)\n",
    "        self.b6 = Block_Regular(32, 32, 16)\n",
    "\n",
    "        # Third megablock which takes in 32 channels and outputs 64 channels, H/W reduced 16--> 8\n",
    "        self.b7 = Block_Identity(32, 64, 16)\n",
    "        self.b8 = Block_Regular(64, 64, 8)\n",
    "        self.b9 = Block_Regular(64, 64, 8)\n",
    "\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "\n",
    "        self._initialize_weights()\n",
    "        \n",
    "        # Initial Conv\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(16)\n",
    "        self.aap = nn.AdaptiveAvgPool2d((1,1))\n",
    "        \n",
    "    def swish(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # Initial conv\n",
    "        x = self.swish(self.bn1(self.conv1(x)))\n",
    "\n",
    "        # Blocks\n",
    "        x = self.b1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.b3(x)\n",
    "        #print(x.shape)\n",
    "        x = self.b4(x)\n",
    "        x = self.b5(x)\n",
    "        x = self.b6(x)\n",
    "        x = self.b7(x)\n",
    "        x = self.b8(x)\n",
    "        x = self.b9(x)\n",
    "\n",
    "        # Pooling and FC\n",
    "        x = self.aap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode = 'fan_in')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                nn.init.kaiming_normal_(m.weight, mode = 'fan_in')\n",
    "                #m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on GPU...\n"
     ]
    }
   ],
   "source": [
    "# Specify the device for computation\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "net = ResNet()\n",
    "net = net.to(device)\n",
    "if device =='cuda':\n",
    "    print(\"Train on GPU...\")\n",
    "else:\n",
    "    print(\"Train on CPU...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass successful\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "# Test forward pass\n",
    "data_check = torch.randn(size=[5,3,32,32])\n",
    "data_check = data_check.to(device)\n",
    "# Forward pass \"data_check\" through \"net\" to get output \"out\"\n",
    "out_check =  net.forward(data_check)\n",
    "# Check output shape\n",
    "assert(out_check.detach().shape == (5,10))\n",
    "print(\"Forward pass successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify preprocessing function.\n",
    "# Reference mean/std value for \n",
    "transform_train  = transforms.Compose([ \n",
    "        transforms.RandomCrop(32, padding = 4),\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/cifar10_trainval_F20.zip\n",
      "Extracting ./data/cifar10_trainval_F20.zip to ./data\n",
      "Files already downloaded and verified\n",
      "Training dataset has 45000 examples!\n",
      "Using downloaded and verified file: ./data/cifar10_trainval_F20.zip\n",
      "Extracting ./data/cifar10_trainval_F20.zip to ./data\n",
      "Files already downloaded and verified\n",
      "Validation dataset has 5000 examples!\n"
     ]
    }
   ],
   "source": [
    "# You cannot change this line.\n",
    "from tools.dataloader import CIFAR10\n",
    "# Call the dataset Loader\n",
    "DATAROOT = \"./data\"\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "VAL_BATCH_SIZE = 100\n",
    "trainset = CIFAR10(root=DATAROOT, train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=TRAIN_BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "valset = CIFAR10(root=DATAROOT, train=False, download=True, transform=transform_val)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=VAL_BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial learning rate\n",
    "INITIAL_LR = 0.2\n",
    "# Momentum for optimizer.\n",
    "MOMENTUM = 0.9\n",
    "# Regularization\n",
    "REG = 1e-5\n",
    "# Total number of training epochs\n",
    "EPOCHS = 105\n",
    "# Learning rate decay policy.\n",
    "DECAY_EPOCHS = 25\n",
    "DECAY = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './saved_model/model.h5'\n",
      "Training from scratch ...\n",
      "Starting from learning rate 0.200000:\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = \"./saved_model\"\n",
    "# FLAG for loading the pretrained model\n",
    "TRAIN_FROM_SCRATCH = True\n",
    "# Code for loading checkpoint and recover epoch id.\n",
    "CKPT_PATH = \"./saved_model/model.h5\"\n",
    "def get_checkpoint(ckpt_path):\n",
    "    try:\n",
    "        ckpt = torch.load(ckpt_path)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    return ckpt\n",
    "\n",
    "ckpt = get_checkpoint(CKPT_PATH)\n",
    "if ckpt is None or TRAIN_FROM_SCRATCH:\n",
    "    if not TRAIN_FROM_SCRATCH:\n",
    "        print(\"Checkpoint not found.\")\n",
    "    print(\"Training from scratch ...\")\n",
    "    start_epoch = 0\n",
    "    current_learning_rate = INITIAL_LR\n",
    "else:\n",
    "    print(\"Successfully loaded checkpoint: %s\" %CKPT_PATH)\n",
    "    net.load_state_dict(ckpt['net'])\n",
    "    start_epoch = ckpt['epoch'] + 1\n",
    "    current_learning_rate = ckpt['lr']\n",
    "    print(\"Starting from epoch %d \" %start_epoch)\n",
    "\n",
    "print(\"Starting from learning rate %f:\" %current_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function and specify regularization\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# Add optimizer\n",
    "optimizer = optim.SGD(params=net.parameters(), lr=current_learning_rate, momentum=MOMENTUM, weight_decay=REG, nesterov=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-20 20:31:47.100227\n",
      "Epoch 0:\n",
      "loss: 2.573115348815918\n",
      "Training loss: 1.6330, Training accuracy: 0.3905\n",
      "2020-09-20 20:32:12.840393\n",
      "Validation...\n",
      "Validation loss: 1.3850, Validation accuracy: 0.4878\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:32:14.793291\n",
      "Epoch 1:\n",
      "loss: 1.3941386938095093\n",
      "Training loss: 1.1344, Training accuracy: 0.5905\n",
      "2020-09-20 20:32:39.330969\n",
      "Validation...\n",
      "Validation loss: 1.0271, Validation accuracy: 0.6454\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:32:41.057869\n",
      "Epoch 2:\n",
      "loss: 1.1286301612854004\n",
      "Training loss: 0.8829, Training accuracy: 0.6890\n",
      "2020-09-20 20:33:04.294330\n",
      "Validation...\n",
      "Validation loss: 0.9909, Validation accuracy: 0.6788\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:33:05.876150\n",
      "Epoch 3:\n",
      "loss: 0.7484288811683655\n",
      "Training loss: 0.7459, Training accuracy: 0.7383\n",
      "2020-09-20 20:33:29.538434\n",
      "Validation...\n",
      "Validation loss: 0.8309, Validation accuracy: 0.7262\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:33:31.133917\n",
      "Epoch 4:\n",
      "loss: 0.6775314211845398\n",
      "Training loss: 0.6582, Training accuracy: 0.7709\n",
      "2020-09-20 20:33:53.528131\n",
      "Validation...\n",
      "Validation loss: 0.6697, Validation accuracy: 0.7738\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:33:55.464471\n",
      "Epoch 5:\n",
      "loss: 0.54944908618927\n",
      "Training loss: 0.5955, Training accuracy: 0.7927\n",
      "2020-09-20 20:34:20.632838\n",
      "Validation...\n",
      "Validation loss: 0.6017, Validation accuracy: 0.7962\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:34:22.411602\n",
      "Epoch 6:\n",
      "loss: 0.6069495677947998\n",
      "Training loss: 0.5440, Training accuracy: 0.8105\n",
      "2020-09-20 20:34:45.933376\n",
      "Validation...\n",
      "Validation loss: 0.5951, Validation accuracy: 0.8080\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:34:47.848271\n",
      "Epoch 7:\n",
      "loss: 0.41481754183769226\n",
      "Training loss: 0.5062, Training accuracy: 0.8250\n",
      "2020-09-20 20:35:13.012947\n",
      "Validation...\n",
      "Validation loss: 0.5769, Validation accuracy: 0.8066\n",
      "\n",
      "2020-09-20 20:35:14.596202\n",
      "Epoch 8:\n",
      "loss: 0.3955325782299042\n",
      "Training loss: 0.4737, Training accuracy: 0.8345\n",
      "2020-09-20 20:35:38.541008\n",
      "Validation...\n",
      "Validation loss: 0.5585, Validation accuracy: 0.8194\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:35:40.287122\n",
      "Epoch 9:\n",
      "loss: 0.5076329112052917\n",
      "Training loss: 0.4516, Training accuracy: 0.8421\n",
      "2020-09-20 20:36:06.162207\n",
      "Validation...\n",
      "Validation loss: 0.5305, Validation accuracy: 0.8194\n",
      "\n",
      "2020-09-20 20:36:07.802234\n",
      "Epoch 10:\n",
      "loss: 0.3499267101287842\n",
      "Training loss: 0.4236, Training accuracy: 0.8531\n",
      "2020-09-20 20:36:33.302093\n",
      "Validation...\n",
      "Validation loss: 0.6243, Validation accuracy: 0.8076\n",
      "\n",
      "2020-09-20 20:36:34.993092\n",
      "Epoch 11:\n",
      "loss: 0.46893182396888733\n",
      "Training loss: 0.4037, Training accuracy: 0.8599\n",
      "2020-09-20 20:37:02.277850\n",
      "Validation...\n",
      "Validation loss: 0.5742, Validation accuracy: 0.8198\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:37:03.847858\n",
      "Epoch 12:\n",
      "loss: 0.3100416362285614\n",
      "Training loss: 0.3899, Training accuracy: 0.8642\n",
      "2020-09-20 20:37:28.994422\n",
      "Validation...\n",
      "Validation loss: 0.4678, Validation accuracy: 0.8460\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:37:30.683997\n",
      "Epoch 13:\n",
      "loss: 0.3900773227214813\n",
      "Training loss: 0.3647, Training accuracy: 0.8732\n",
      "2020-09-20 20:37:55.032479\n",
      "Validation...\n",
      "Validation loss: 0.4304, Validation accuracy: 0.8548\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:37:56.663676\n",
      "Epoch 14:\n",
      "loss: 0.363860160112381\n",
      "Training loss: 0.3528, Training accuracy: 0.8758\n",
      "2020-09-20 20:38:19.729642\n",
      "Validation...\n",
      "Validation loss: 0.4342, Validation accuracy: 0.8606\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:38:21.302789\n",
      "Epoch 15:\n",
      "loss: 0.30752846598625183\n",
      "Training loss: 0.3401, Training accuracy: 0.8817\n",
      "2020-09-20 20:38:45.418721\n",
      "Validation...\n",
      "Validation loss: 0.4266, Validation accuracy: 0.8594\n",
      "\n",
      "2020-09-20 20:38:47.026392\n",
      "Epoch 16:\n",
      "loss: 0.3940240144729614\n",
      "Training loss: 0.3280, Training accuracy: 0.8843\n",
      "2020-09-20 20:39:12.755916\n",
      "Validation...\n",
      "Validation loss: 0.4374, Validation accuracy: 0.8562\n",
      "\n",
      "2020-09-20 20:39:14.275113\n",
      "Epoch 17:\n",
      "loss: 0.2503955662250519\n",
      "Training loss: 0.3142, Training accuracy: 0.8894\n",
      "2020-09-20 20:39:37.222916\n",
      "Validation...\n",
      "Validation loss: 0.4599, Validation accuracy: 0.8516\n",
      "\n",
      "2020-09-20 20:39:38.778785\n",
      "Epoch 18:\n",
      "loss: 0.28560957312583923\n",
      "Training loss: 0.3003, Training accuracy: 0.8933\n",
      "2020-09-20 20:40:05.049446\n",
      "Validation...\n",
      "Validation loss: 0.4453, Validation accuracy: 0.8606\n",
      "\n",
      "2020-09-20 20:40:06.747738\n",
      "Epoch 19:\n",
      "loss: 0.27537429332733154\n",
      "Training loss: 0.2920, Training accuracy: 0.8973\n",
      "2020-09-20 20:40:33.063658\n",
      "Validation...\n",
      "Validation loss: 0.4043, Validation accuracy: 0.8710\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:40:34.807707\n",
      "Epoch 20:\n",
      "loss: 0.23269489407539368\n",
      "Training loss: 0.2821, Training accuracy: 0.9004\n",
      "2020-09-20 20:41:01.620618\n",
      "Validation...\n",
      "Validation loss: 0.5163, Validation accuracy: 0.8312\n",
      "\n",
      "2020-09-20 20:41:03.055907\n",
      "Epoch 21:\n",
      "loss: 0.3866278827190399\n",
      "Training loss: 0.2752, Training accuracy: 0.9022\n",
      "2020-09-20 20:41:27.287593\n",
      "Validation...\n",
      "Validation loss: 0.3879, Validation accuracy: 0.8684\n",
      "\n",
      "2020-09-20 20:41:28.920729\n",
      "Epoch 22:\n",
      "loss: 0.20198285579681396\n",
      "Training loss: 0.2652, Training accuracy: 0.9062\n",
      "2020-09-20 20:41:55.346825\n",
      "Validation...\n",
      "Validation loss: 0.4525, Validation accuracy: 0.8664\n",
      "\n",
      "2020-09-20 20:41:57.186616\n",
      "Epoch 23:\n",
      "loss: 0.29174718260765076\n",
      "Training loss: 0.2557, Training accuracy: 0.9099\n",
      "2020-09-20 20:42:23.908639\n",
      "Validation...\n",
      "Validation loss: 0.4163, Validation accuracy: 0.8672\n",
      "\n",
      "2020-09-20 20:42:25.573940\n",
      "Epoch 24:\n",
      "loss: 0.32316702604293823\n",
      "Training loss: 0.2499, Training accuracy: 0.9112\n",
      "2020-09-20 20:42:52.688958\n",
      "Validation...\n",
      "Validation loss: 0.4426, Validation accuracy: 0.8638\n",
      "\n",
      "2020-09-20 20:42:54.298683\n",
      "Epoch 25:\n",
      "loss: 0.26786166429519653\n",
      "Training loss: 0.2437, Training accuracy: 0.9148\n",
      "2020-09-20 20:43:22.959825\n",
      "Validation...\n",
      "Validation loss: 0.4789, Validation accuracy: 0.8556\n",
      "\n",
      "Current learning rate has decayed to 0.020000\n",
      "2020-09-20 20:43:24.479369\n",
      "Epoch 26:\n",
      "loss: 0.20524786412715912\n",
      "Training loss: 0.1697, Training accuracy: 0.9408\n",
      "2020-09-20 20:43:50.707689\n",
      "Validation...\n",
      "Validation loss: 0.3332, Validation accuracy: 0.8952\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:43:52.301172\n",
      "Epoch 27:\n",
      "loss: 0.08899607509374619\n",
      "Training loss: 0.1467, Training accuracy: 0.9492\n",
      "2020-09-20 20:44:16.527809\n",
      "Validation...\n",
      "Validation loss: 0.3308, Validation accuracy: 0.8986\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:44:18.195237\n",
      "Epoch 28:\n",
      "loss: 0.10154180228710175\n",
      "Training loss: 0.1358, Training accuracy: 0.9524\n",
      "2020-09-20 20:44:41.401817\n",
      "Validation...\n",
      "Validation loss: 0.3346, Validation accuracy: 0.9000\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:44:43.126842\n",
      "Epoch 29:\n",
      "loss: 0.1286778450012207\n",
      "Training loss: 0.1305, Training accuracy: 0.9540\n",
      "2020-09-20 20:45:07.021309\n",
      "Validation...\n",
      "Validation loss: 0.3356, Validation accuracy: 0.9004\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:45:08.603327\n",
      "Epoch 30:\n",
      "loss: 0.10211780667304993\n",
      "Training loss: 0.1296, Training accuracy: 0.9548\n",
      "2020-09-20 20:45:33.772682\n",
      "Validation...\n",
      "Validation loss: 0.3475, Validation accuracy: 0.8980\n",
      "\n",
      "2020-09-20 20:45:35.434935\n",
      "Epoch 31:\n",
      "loss: 0.1322527527809143\n",
      "Training loss: 0.1224, Training accuracy: 0.9576\n",
      "2020-09-20 20:46:02.108230\n",
      "Validation...\n",
      "Validation loss: 0.3425, Validation accuracy: 0.8988\n",
      "\n",
      "2020-09-20 20:46:03.527593\n",
      "Epoch 32:\n",
      "loss: 0.09963822364807129\n",
      "Training loss: 0.1200, Training accuracy: 0.9573\n",
      "2020-09-20 20:46:29.931861\n",
      "Validation...\n",
      "Validation loss: 0.3474, Validation accuracy: 0.9028\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:46:31.834998\n",
      "Epoch 33:\n",
      "loss: 0.15263867378234863\n",
      "Training loss: 0.1139, Training accuracy: 0.9601\n",
      "2020-09-20 20:46:58.312142\n",
      "Validation...\n",
      "Validation loss: 0.3511, Validation accuracy: 0.9032\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:47:00.283181\n",
      "Epoch 34:\n",
      "loss: 0.15319864451885223\n",
      "Training loss: 0.1136, Training accuracy: 0.9608\n",
      "2020-09-20 20:47:27.092135\n",
      "Validation...\n",
      "Validation loss: 0.3494, Validation accuracy: 0.8984\n",
      "\n",
      "2020-09-20 20:47:28.868667\n",
      "Epoch 35:\n",
      "loss: 0.04702725633978844\n",
      "Training loss: 0.1102, Training accuracy: 0.9617\n",
      "2020-09-20 20:47:53.502405\n",
      "Validation...\n",
      "Validation loss: 0.3547, Validation accuracy: 0.9018\n",
      "\n",
      "2020-09-20 20:47:55.109999\n",
      "Epoch 36:\n",
      "loss: 0.05477343127131462\n",
      "Training loss: 0.1048, Training accuracy: 0.9626\n",
      "2020-09-20 20:48:19.842228\n",
      "Validation...\n",
      "Validation loss: 0.3693, Validation accuracy: 0.8978\n",
      "\n",
      "2020-09-20 20:48:21.265364\n",
      "Epoch 37:\n",
      "loss: 0.07111155986785889\n",
      "Training loss: 0.1050, Training accuracy: 0.9637\n",
      "2020-09-20 20:48:49.129472\n",
      "Validation...\n",
      "Validation loss: 0.3721, Validation accuracy: 0.8998\n",
      "\n",
      "2020-09-20 20:48:50.618625\n",
      "Epoch 38:\n",
      "loss: 0.12290690839290619\n",
      "Training loss: 0.1013, Training accuracy: 0.9644\n",
      "2020-09-20 20:49:15.522010\n",
      "Validation...\n",
      "Validation loss: 0.3731, Validation accuracy: 0.9006\n",
      "\n",
      "2020-09-20 20:49:17.334956\n",
      "Epoch 39:\n",
      "loss: 0.09598960727453232\n",
      "Training loss: 0.0982, Training accuracy: 0.9649\n",
      "2020-09-20 20:49:41.358876\n",
      "Validation...\n",
      "Validation loss: 0.3737, Validation accuracy: 0.8978\n",
      "\n",
      "2020-09-20 20:49:42.994534\n",
      "Epoch 40:\n",
      "loss: 0.15123364329338074\n",
      "Training loss: 0.0982, Training accuracy: 0.9659\n",
      "2020-09-20 20:50:06.873750\n",
      "Validation...\n",
      "Validation loss: 0.3815, Validation accuracy: 0.8982\n",
      "\n",
      "2020-09-20 20:50:08.479414\n",
      "Epoch 41:\n",
      "loss: 0.08655504137277603\n",
      "Training loss: 0.0947, Training accuracy: 0.9673\n",
      "2020-09-20 20:50:32.586247\n",
      "Validation...\n",
      "Validation loss: 0.3691, Validation accuracy: 0.9006\n",
      "\n",
      "2020-09-20 20:50:34.232217\n",
      "Epoch 42:\n",
      "loss: 0.08613581955432892\n",
      "Training loss: 0.0942, Training accuracy: 0.9660\n",
      "2020-09-20 20:50:57.429298\n",
      "Validation...\n",
      "Validation loss: 0.3799, Validation accuracy: 0.8988\n",
      "\n",
      "2020-09-20 20:50:59.002202\n",
      "Epoch 43:\n",
      "loss: 0.06345025449991226\n",
      "Training loss: 0.0930, Training accuracy: 0.9671\n",
      "2020-09-20 20:51:22.842229\n",
      "Validation...\n",
      "Validation loss: 0.3826, Validation accuracy: 0.9020\n",
      "\n",
      "2020-09-20 20:51:24.591051\n",
      "Epoch 44:\n",
      "loss: 0.05623561516404152\n",
      "Training loss: 0.0916, Training accuracy: 0.9680\n",
      "2020-09-20 20:51:47.120836\n",
      "Validation...\n",
      "Validation loss: 0.3877, Validation accuracy: 0.8990\n",
      "\n",
      "2020-09-20 20:51:49.066760\n",
      "Epoch 45:\n",
      "loss: 0.055363718420267105\n",
      "Training loss: 0.0864, Training accuracy: 0.9696\n",
      "2020-09-20 20:52:13.727458\n",
      "Validation...\n",
      "Validation loss: 0.3872, Validation accuracy: 0.9022\n",
      "\n",
      "2020-09-20 20:52:15.306868\n",
      "Epoch 46:\n",
      "loss: 0.057060956954956055\n",
      "Training loss: 0.0873, Training accuracy: 0.9691\n",
      "2020-09-20 20:52:38.163325\n",
      "Validation...\n",
      "Validation loss: 0.3935, Validation accuracy: 0.9000\n",
      "\n",
      "2020-09-20 20:52:39.770708\n",
      "Epoch 47:\n",
      "loss: 0.10005921870470047\n",
      "Training loss: 0.0861, Training accuracy: 0.9695\n",
      "2020-09-20 20:53:03.762098\n",
      "Validation...\n",
      "Validation loss: 0.3932, Validation accuracy: 0.8998\n",
      "\n",
      "2020-09-20 20:53:05.541064\n",
      "Epoch 48:\n",
      "loss: 0.10477955639362335\n",
      "Training loss: 0.0822, Training accuracy: 0.9709\n",
      "2020-09-20 20:53:30.732181\n",
      "Validation...\n",
      "Validation loss: 0.4013, Validation accuracy: 0.8994\n",
      "\n",
      "2020-09-20 20:53:32.326830\n",
      "Epoch 49:\n",
      "loss: 0.060844987630844116\n",
      "Training loss: 0.0811, Training accuracy: 0.9718\n",
      "2020-09-20 20:53:57.267621\n",
      "Validation...\n",
      "Validation loss: 0.3979, Validation accuracy: 0.9030\n",
      "\n",
      "2020-09-20 20:53:58.938620\n",
      "Epoch 50:\n",
      "loss: 0.05916624516248703\n",
      "Training loss: 0.0805, Training accuracy: 0.9707\n",
      "2020-09-20 20:54:23.319326\n",
      "Validation...\n",
      "Validation loss: 0.4012, Validation accuracy: 0.9028\n",
      "\n",
      "Current learning rate has decayed to 0.002000\n",
      "2020-09-20 20:54:24.864801\n",
      "Epoch 51:\n",
      "loss: 0.07144748419523239\n",
      "Training loss: 0.0757, Training accuracy: 0.9736\n",
      "2020-09-20 20:54:46.246189\n",
      "Validation...\n",
      "Validation loss: 0.3975, Validation accuracy: 0.9026\n",
      "\n",
      "2020-09-20 20:54:47.822485\n",
      "Epoch 52:\n",
      "loss: 0.07254485040903091\n",
      "Training loss: 0.0723, Training accuracy: 0.9744\n",
      "2020-09-20 20:55:11.227112\n",
      "Validation...\n",
      "Validation loss: 0.3952, Validation accuracy: 0.9028\n",
      "\n",
      "2020-09-20 20:55:12.866789\n",
      "Epoch 53:\n",
      "loss: 0.059833116829395294\n",
      "Training loss: 0.0714, Training accuracy: 0.9747\n",
      "2020-09-20 20:55:39.268622\n",
      "Validation...\n",
      "Validation loss: 0.3952, Validation accuracy: 0.9036\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:55:40.972883\n",
      "Epoch 54:\n",
      "loss: 0.04358317330479622\n",
      "Training loss: 0.0688, Training accuracy: 0.9761\n",
      "2020-09-20 20:56:06.889213\n",
      "Validation...\n",
      "Validation loss: 0.3985, Validation accuracy: 0.9032\n",
      "\n",
      "2020-09-20 20:56:08.807113\n",
      "Epoch 55:\n",
      "loss: 0.07897181063890457\n",
      "Training loss: 0.0699, Training accuracy: 0.9758\n",
      "2020-09-20 20:56:35.727597\n",
      "Validation...\n",
      "Validation loss: 0.4038, Validation accuracy: 0.9024\n",
      "\n",
      "2020-09-20 20:56:37.308466\n",
      "Epoch 56:\n",
      "loss: 0.07337247580289841\n",
      "Training loss: 0.0678, Training accuracy: 0.9768\n",
      "2020-09-20 20:57:04.728542\n",
      "Validation...\n",
      "Validation loss: 0.3994, Validation accuracy: 0.9040\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:57:06.727179\n",
      "Epoch 57:\n",
      "loss: 0.027029454708099365\n",
      "Training loss: 0.0673, Training accuracy: 0.9766\n",
      "2020-09-20 20:57:34.743965\n",
      "Validation...\n",
      "Validation loss: 0.3985, Validation accuracy: 0.9046\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:57:36.434485\n",
      "Epoch 58:\n",
      "loss: 0.053355805575847626\n",
      "Training loss: 0.0680, Training accuracy: 0.9764\n",
      "2020-09-20 20:58:03.410565\n",
      "Validation...\n",
      "Validation loss: 0.3971, Validation accuracy: 0.9052\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:58:05.144456\n",
      "Epoch 59:\n",
      "loss: 0.06416743993759155\n",
      "Training loss: 0.0674, Training accuracy: 0.9766\n",
      "2020-09-20 20:58:32.348145\n",
      "Validation...\n",
      "Validation loss: 0.4004, Validation accuracy: 0.9050\n",
      "\n",
      "2020-09-20 20:58:34.173957\n",
      "Epoch 60:\n",
      "loss: 0.06603424996137619\n",
      "Training loss: 0.0664, Training accuracy: 0.9770\n",
      "2020-09-20 20:58:59.951776\n",
      "Validation...\n",
      "Validation loss: 0.4045, Validation accuracy: 0.9038\n",
      "\n",
      "2020-09-20 20:59:01.646581\n",
      "Epoch 61:\n",
      "loss: 0.023232579231262207\n",
      "Training loss: 0.0678, Training accuracy: 0.9762\n",
      "2020-09-20 20:59:25.069467\n",
      "Validation...\n",
      "Validation loss: 0.4011, Validation accuracy: 0.9054\n",
      "\n",
      "Saving ...\n",
      "\n",
      "2020-09-20 20:59:26.819268\n",
      "Epoch 62:\n",
      "loss: 0.04540766403079033\n",
      "Training loss: 0.0669, Training accuracy: 0.9771\n",
      "2020-09-20 20:59:52.183789\n",
      "Validation...\n",
      "Validation loss: 0.4040, Validation accuracy: 0.9046\n",
      "\n",
      "2020-09-20 20:59:53.735127\n",
      "Epoch 63:\n",
      "loss: 0.05156976729631424\n",
      "Training loss: 0.0650, Training accuracy: 0.9771\n",
      "2020-09-20 21:00:18.055390\n",
      "Validation...\n",
      "Validation loss: 0.4005, Validation accuracy: 0.9024\n",
      "\n",
      "2020-09-20 21:00:19.660918\n",
      "Epoch 64:\n",
      "loss: 0.07033847272396088\n",
      "Training loss: 0.0670, Training accuracy: 0.9765\n",
      "2020-09-20 21:00:41.913990\n",
      "Validation...\n",
      "Validation loss: 0.4063, Validation accuracy: 0.9028\n",
      "\n",
      "2020-09-20 21:00:43.471562\n",
      "Epoch 65:\n",
      "loss: 0.04929447919130325\n",
      "Training loss: 0.0641, Training accuracy: 0.9776\n",
      "2020-09-20 21:01:07.752034\n",
      "Validation...\n",
      "Validation loss: 0.4057, Validation accuracy: 0.9024\n",
      "\n",
      "2020-09-20 21:01:09.544777\n",
      "Epoch 66:\n",
      "loss: 0.03775045648217201\n",
      "Training loss: 0.0669, Training accuracy: 0.9760\n",
      "2020-09-20 21:01:33.727430\n",
      "Validation...\n",
      "Validation loss: 0.4051, Validation accuracy: 0.9040\n",
      "\n",
      "2020-09-20 21:01:35.550431\n",
      "Epoch 67:\n",
      "loss: 0.06996815651655197\n",
      "Training loss: 0.0655, Training accuracy: 0.9777\n",
      "2020-09-20 21:01:59.501199\n",
      "Validation...\n",
      "Validation loss: 0.4029, Validation accuracy: 0.9044\n",
      "\n",
      "2020-09-20 21:02:01.193567\n",
      "Epoch 68:\n",
      "loss: 0.11238232254981995\n",
      "Training loss: 0.0655, Training accuracy: 0.9773\n",
      "2020-09-20 21:02:24.317371\n",
      "Validation...\n",
      "Validation loss: 0.4008, Validation accuracy: 0.9046\n",
      "\n",
      "2020-09-20 21:02:26.054955\n",
      "Epoch 69:\n",
      "loss: 0.03034045174717903\n",
      "Training loss: 0.0664, Training accuracy: 0.9766\n",
      "2020-09-20 21:02:48.531208\n",
      "Validation...\n",
      "Validation loss: 0.4028, Validation accuracy: 0.9032\n",
      "\n",
      "2020-09-20 21:02:50.331434\n",
      "Epoch 70:\n",
      "loss: 0.0805158019065857\n",
      "Training loss: 0.0650, Training accuracy: 0.9774\n",
      "2020-09-20 21:03:12.875560\n",
      "Validation...\n",
      "Validation loss: 0.4048, Validation accuracy: 0.9046\n",
      "\n",
      "2020-09-20 21:03:14.443266\n",
      "Epoch 71:\n",
      "loss: 0.06229468435049057\n",
      "Training loss: 0.0655, Training accuracy: 0.9776\n",
      "2020-09-20 21:03:41.081055\n",
      "Validation...\n",
      "Validation loss: 0.4076, Validation accuracy: 0.9036\n",
      "\n",
      "2020-09-20 21:03:42.965877\n",
      "Epoch 72:\n",
      "loss: 0.06930352747440338\n",
      "Training loss: 0.0631, Training accuracy: 0.9785\n",
      "2020-09-20 21:04:09.295390\n",
      "Validation...\n",
      "Validation loss: 0.4105, Validation accuracy: 0.9034\n",
      "\n",
      "2020-09-20 21:04:11.075586\n",
      "Epoch 73:\n",
      "loss: 0.06521180272102356\n",
      "Training loss: 0.0629, Training accuracy: 0.9786\n",
      "2020-09-20 21:04:36.361305\n",
      "Validation...\n",
      "Validation loss: 0.4097, Validation accuracy: 0.9022\n",
      "\n",
      "2020-09-20 21:04:37.912726\n",
      "Epoch 74:\n",
      "loss: 0.07317136228084564\n",
      "Training loss: 0.0648, Training accuracy: 0.9780\n",
      "2020-09-20 21:05:04.966692\n",
      "Validation...\n",
      "Validation loss: 0.4146, Validation accuracy: 0.9024\n",
      "\n",
      "2020-09-20 21:05:06.639835\n",
      "Epoch 75:\n",
      "loss: 0.05856145918369293\n",
      "Training loss: 0.0642, Training accuracy: 0.9778\n",
      "2020-09-20 21:05:31.246664\n",
      "Validation...\n",
      "Validation loss: 0.4074, Validation accuracy: 0.9034\n",
      "\n",
      "Current learning rate has decayed to 0.000200\n",
      "2020-09-20 21:05:32.892666\n",
      "Epoch 76:\n",
      "loss: 0.08496706187725067\n",
      "Training loss: 0.0617, Training accuracy: 0.9787\n",
      "2020-09-20 21:05:56.233228\n",
      "Validation...\n",
      "Validation loss: 0.4081, Validation accuracy: 0.9032\n",
      "\n",
      "2020-09-20 21:05:57.810948\n",
      "Epoch 77:\n",
      "loss: 0.09125368297100067\n",
      "Training loss: 0.0608, Training accuracy: 0.9788\n",
      "2020-09-20 21:06:24.558464\n",
      "Validation...\n",
      "Validation loss: 0.4117, Validation accuracy: 0.9014\n",
      "\n",
      "2020-09-20 21:06:26.339325\n",
      "Epoch 78:\n",
      "loss: 0.04551393538713455\n",
      "Training loss: 0.0642, Training accuracy: 0.9784\n",
      "2020-09-20 21:06:51.900589\n",
      "Validation...\n",
      "Validation loss: 0.4089, Validation accuracy: 0.9032\n",
      "\n",
      "2020-09-20 21:06:53.543408\n",
      "Epoch 79:\n",
      "loss: 0.049187980592250824\n",
      "Training loss: 0.0628, Training accuracy: 0.9781\n",
      "2020-09-20 21:07:17.631818\n",
      "Validation...\n",
      "Validation loss: 0.4081, Validation accuracy: 0.9034\n",
      "\n",
      "2020-09-20 21:07:19.285560\n",
      "Epoch 80:\n",
      "loss: 0.06203031912446022\n",
      "Training loss: 0.0641, Training accuracy: 0.9779\n",
      "2020-09-20 21:07:44.539896\n",
      "Validation...\n",
      "Validation loss: 0.4091, Validation accuracy: 0.9022\n",
      "\n",
      "2020-09-20 21:07:46.279394\n",
      "Epoch 81:\n",
      "loss: 0.04836862161755562\n",
      "Training loss: 0.0644, Training accuracy: 0.9780\n",
      "2020-09-20 21:08:11.824085\n",
      "Validation...\n",
      "Validation loss: 0.4091, Validation accuracy: 0.9034\n",
      "\n",
      "2020-09-20 21:08:13.551774\n",
      "Epoch 82:\n",
      "loss: 0.0452229343354702\n",
      "Training loss: 0.0636, Training accuracy: 0.9778\n",
      "2020-09-20 21:08:39.202432\n",
      "Validation...\n",
      "Validation loss: 0.4095, Validation accuracy: 0.9026\n",
      "\n",
      "2020-09-20 21:08:40.952131\n",
      "Epoch 83:\n",
      "loss: 0.029500402510166168\n",
      "Training loss: 0.0615, Training accuracy: 0.9786\n",
      "2020-09-20 21:09:07.131354\n",
      "Validation...\n",
      "Validation loss: 0.4069, Validation accuracy: 0.9042\n",
      "\n",
      "2020-09-20 21:09:08.874149\n",
      "Epoch 84:\n",
      "loss: 0.07791699469089508\n",
      "Training loss: 0.0612, Training accuracy: 0.9787\n",
      "2020-09-20 21:09:32.468339\n",
      "Validation...\n",
      "Validation loss: 0.4095, Validation accuracy: 0.9036\n",
      "\n",
      "2020-09-20 21:09:34.267591\n",
      "Epoch 85:\n",
      "loss: 0.046135399490594864\n",
      "Training loss: 0.0636, Training accuracy: 0.9773\n",
      "2020-09-20 21:09:59.595641\n",
      "Validation...\n",
      "Validation loss: 0.4105, Validation accuracy: 0.9028\n",
      "\n",
      "2020-09-20 21:10:01.334991\n",
      "Epoch 86:\n",
      "loss: 0.03215072304010391\n",
      "Training loss: 0.0635, Training accuracy: 0.9786\n",
      "2020-09-20 21:10:28.237776\n",
      "Validation...\n",
      "Validation loss: 0.4091, Validation accuracy: 0.9042\n",
      "\n",
      "2020-09-20 21:10:29.760237\n",
      "Epoch 87:\n",
      "loss: 0.051107343286275864\n",
      "Training loss: 0.0614, Training accuracy: 0.9785\n",
      "2020-09-20 21:10:57.287980\n",
      "Validation...\n",
      "Validation loss: 0.4085, Validation accuracy: 0.9034\n",
      "\n",
      "2020-09-20 21:10:58.935593\n",
      "Epoch 88:\n",
      "loss: 0.09581810981035233\n",
      "Training loss: 0.0631, Training accuracy: 0.9777\n",
      "2020-09-20 21:11:25.117739\n",
      "Validation...\n",
      "Validation loss: 0.4124, Validation accuracy: 0.9026\n",
      "\n",
      "2020-09-20 21:11:26.667238\n",
      "Epoch 89:\n",
      "loss: 0.07766667008399963\n",
      "Training loss: 0.0608, Training accuracy: 0.9795\n",
      "2020-09-20 21:11:51.797434\n",
      "Validation...\n",
      "Validation loss: 0.4116, Validation accuracy: 0.9026\n",
      "\n",
      "2020-09-20 21:11:53.410730\n",
      "Epoch 90:\n",
      "loss: 0.07858440279960632\n",
      "Training loss: 0.0618, Training accuracy: 0.9789\n",
      "2020-09-20 21:12:19.954597\n",
      "Validation...\n",
      "Validation loss: 0.4116, Validation accuracy: 0.9026\n",
      "\n",
      "2020-09-20 21:12:21.768324\n",
      "Epoch 91:\n",
      "loss: 0.030917618423700333\n",
      "Training loss: 0.0623, Training accuracy: 0.9776\n",
      "2020-09-20 21:12:48.114287\n",
      "Validation...\n",
      "Validation loss: 0.4134, Validation accuracy: 0.9028\n",
      "\n",
      "2020-09-20 21:12:49.883442\n",
      "Epoch 92:\n",
      "loss: 0.10626044869422913\n",
      "Training loss: 0.0647, Training accuracy: 0.9773\n",
      "2020-09-20 21:13:13.703253\n",
      "Validation...\n",
      "Validation loss: 0.4133, Validation accuracy: 0.9044\n",
      "\n",
      "2020-09-20 21:13:15.373217\n",
      "Epoch 93:\n",
      "loss: 0.05126364529132843\n",
      "Training loss: 0.0636, Training accuracy: 0.9783\n",
      "2020-09-20 21:13:41.074212\n",
      "Validation...\n",
      "Validation loss: 0.4146, Validation accuracy: 0.9026\n",
      "\n",
      "2020-09-20 21:13:43.035122\n",
      "Epoch 94:\n",
      "loss: 0.06834366917610168\n",
      "Training loss: 0.0634, Training accuracy: 0.9775\n",
      "2020-09-20 21:14:09.230992\n",
      "Validation...\n",
      "Validation loss: 0.4115, Validation accuracy: 0.9022\n",
      "\n",
      "2020-09-20 21:14:11.047565\n",
      "Epoch 95:\n",
      "loss: 0.075955830514431\n",
      "Training loss: 0.0620, Training accuracy: 0.9783\n",
      "2020-09-20 21:14:37.227011\n",
      "Validation...\n",
      "Validation loss: 0.4111, Validation accuracy: 0.9036\n",
      "\n",
      "2020-09-20 21:14:38.976421\n",
      "Epoch 96:\n",
      "loss: 0.06731447577476501\n",
      "Training loss: 0.0617, Training accuracy: 0.9789\n",
      "2020-09-20 21:15:04.095978\n",
      "Validation...\n",
      "Validation loss: 0.4104, Validation accuracy: 0.9042\n",
      "\n",
      "2020-09-20 21:15:05.755707\n",
      "Epoch 97:\n",
      "loss: 0.060312457382678986\n",
      "Training loss: 0.0631, Training accuracy: 0.9787\n",
      "2020-09-20 21:15:32.516218\n",
      "Validation...\n",
      "Validation loss: 0.4091, Validation accuracy: 0.9028\n",
      "\n",
      "2020-09-20 21:15:34.327441\n",
      "Epoch 98:\n",
      "loss: 0.09913431107997894\n",
      "Training loss: 0.0619, Training accuracy: 0.9778\n",
      "2020-09-20 21:15:59.953150\n",
      "Validation...\n",
      "Validation loss: 0.4107, Validation accuracy: 0.9036\n",
      "\n",
      "2020-09-20 21:16:01.755024\n",
      "Epoch 99:\n",
      "loss: 0.034338049590587616\n",
      "Training loss: 0.0629, Training accuracy: 0.9780\n",
      "2020-09-20 21:16:28.674566\n",
      "Validation...\n",
      "Validation loss: 0.4123, Validation accuracy: 0.9014\n",
      "\n",
      "2020-09-20 21:16:30.499451\n",
      "Epoch 100:\n",
      "loss: 0.049565430730581284\n",
      "Training loss: 0.0625, Training accuracy: 0.9788\n",
      "2020-09-20 21:16:55.557825\n",
      "Validation...\n",
      "Validation loss: 0.4174, Validation accuracy: 0.9036\n",
      "\n",
      "Current learning rate has decayed to 0.000020\n",
      "2020-09-20 21:16:57.465766\n",
      "Epoch 101:\n",
      "loss: 0.05018462613224983\n",
      "Training loss: 0.0629, Training accuracy: 0.9778\n",
      "2020-09-20 21:17:21.917425\n",
      "Validation...\n",
      "Validation loss: 0.4112, Validation accuracy: 0.9026\n",
      "\n",
      "2020-09-20 21:17:23.515407\n",
      "Epoch 102:\n",
      "loss: 0.020237650722265244\n",
      "Training loss: 0.0603, Training accuracy: 0.9793\n",
      "2020-09-20 21:17:47.354415\n",
      "Validation...\n",
      "Validation loss: 0.4097, Validation accuracy: 0.9010\n",
      "\n",
      "2020-09-20 21:17:48.863161\n",
      "Epoch 103:\n",
      "loss: 0.08706605434417725\n",
      "Training loss: 0.0631, Training accuracy: 0.9780\n",
      "2020-09-20 21:18:11.651007\n",
      "Validation...\n",
      "Validation loss: 0.4104, Validation accuracy: 0.9038\n",
      "\n",
      "2020-09-20 21:18:13.236636\n",
      "Epoch 104:\n",
      "loss: 0.04014432057738304\n",
      "Training loss: 0.0621, Training accuracy: 0.9786\n",
      "2020-09-20 21:18:35.813410\n",
      "Validation...\n",
      "Validation loss: 0.4107, Validation accuracy: 0.9042\n",
      "\n",
      "Optimization finished.\n"
     ]
    }
   ],
   "source": [
    "# Start the training/validation process\n",
    "# The process should take about 5 minutes on a GTX 1070-Ti\n",
    "# if the code is written efficiently.\n",
    "\n",
    "lamb = 0.5\n",
    "\n",
    "global_step = 0\n",
    "best_val_acc = 0\n",
    "\n",
    "train_acc_l, val_acc_l = [],[]\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "for i in range(start_epoch, EPOCHS):\n",
    "    print(datetime.datetime.now())\n",
    "    # Switch to train mode\n",
    "    net.train()\n",
    "    print(\"Epoch %d:\" %i)\n",
    "\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    # Train the training dataset for 1 epoch.\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        # Copy inputs to device\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        # Zero the gradient\n",
    "        optimizer.zero_grad()\n",
    "        # Generate output\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        ### L1 regularization\n",
    "        #for name, param in net.named_parameters():\n",
    "        #    if name.endswith('weight'):\n",
    "        #        print(name, param)\n",
    "        #        L1_pre = Variable(param, requires_grad = True)\n",
    "        #        L1 = torch.norm(L1_pre, 1)\n",
    "        #loss = criterion(outputs, targets) + (L1 * lamb)\n",
    "        \n",
    "        loss = criterion(outputs, targets) \n",
    "        \n",
    "        # Now backward loss\n",
    "        loss.backward()\n",
    "        # Print initial loss\n",
    "        if batch_idx == 0:\n",
    "            print(f'loss: {loss}')\n",
    "        # Apply gradient\n",
    "        optimizer.step()\n",
    "        # Calculate predicted labels\n",
    "        _, predicted = outputs.max(1)\n",
    "        total_examples += predicted.size(0)\n",
    "        correct_examples += predicted.eq(targets).sum().item()\n",
    "        train_loss += loss\n",
    "        global_step += 1\n",
    "                \n",
    "    avg_loss = train_loss / (batch_idx + 1)\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    print(\"Training loss: %.4f, Training accuracy: %.4f\" %(avg_loss, avg_acc))\n",
    "    train_acc_l.append(avg_acc)\n",
    "    print(datetime.datetime.now())\n",
    "    # Validate on the validation dataset\n",
    "    print(\"Validation...\")\n",
    "    total_examples = 0\n",
    "    correct_examples = 0\n",
    "    \n",
    "    net.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    # Disable gradient during validation\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(valloader):\n",
    "            # Copy inputs to device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            # Zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "            # Generate output from the DNN.\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)            \n",
    "            # Calculate predicted labels\n",
    "            _, predicted = outputs.max(1)\n",
    "            total_examples += predicted.size(0)\n",
    "            correct_examples += predicted.eq(targets).sum().item()\n",
    "            val_loss += loss\n",
    "\n",
    "    avg_loss = val_loss / len(valloader)\n",
    "    avg_acc = correct_examples / total_examples\n",
    "    val_acc_l.append(avg_acc)\n",
    "    \n",
    "    print(\"Validation loss: %.4f, Validation accuracy: %.4f\\n\" % (avg_loss, avg_acc))\n",
    "\n",
    "    # Handle the learning rate scheduler.\n",
    "    if i % DECAY_EPOCHS == 0 and i != 0:\n",
    "        current_learning_rate = current_learning_rate * DECAY\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = current_learning_rate\n",
    "        print(\"Current learning rate has decayed to %f\" %current_learning_rate)\n",
    "    \n",
    "    # Save for checkpoint\n",
    "    if avg_acc > best_val_acc:\n",
    "        best_val_acc = avg_acc\n",
    "        if not os.path.exists(CHECKPOINT_PATH):\n",
    "            os.makedirs(CHECKPOINT_PATH)\n",
    "        print(\"Saving ...\\n\")\n",
    "        state = {'net': net.state_dict(),\n",
    "                 'epoch': i,\n",
    "                 'lr': current_learning_rate}\n",
    "        torch.save(state, os.path.join(CHECKPOINT_PATH, 'model.h5'))\n",
    "\n",
    "print(\"Optimization finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.dropbox.com/s/vaeeg2zf6kovxpp/cifar10_test_F20.zip?dl=1 to ./data/cifar10_test_F20.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0515011d06d47c58b79551ede7f4954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar10_test_F20.zip to ./data\n",
      "Files already downloaded and verified\n",
      "Testing dataset has 10000 examples!\n"
     ]
    }
   ],
   "source": [
    "from tools.dataloader_test import CIFAR10\n",
    "testset = CIFAR10(root='./data', train=False,\n",
    "                        download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (b1): Block_Regular(\n",
       "    (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (b2): Block_Regular(\n",
       "    (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (b3): Block_Regular(\n",
       "    (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (b4): Block_Identity(\n",
       "    (conv3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_down): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2))\n",
       "    (bn_down): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (b5): Block_Regular(\n",
       "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (b6): Block_Regular(\n",
       "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (b7): Block_Identity(\n",
       "    (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_down): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2))\n",
       "    (bn_down): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (b8): Block_Regular(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (b9): Block_Regular(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (aap): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet()\n",
    "model.load_state_dict(torch.load('saved_model/ResNet_best.h5')['net'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            # Copy inputs to device\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            # Generate output from the DNN.\n",
    "            outputs = net(inputs)            \n",
    "            # Calculate predicted labels\n",
    "            _, predicted = outputs.max(1)\n",
    "            pred.append(predicted.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(pred)\n",
    "pred = pred.flatten()\n",
    "\n",
    "IDs = list(range(len(pred)))\n",
    "dictionary = dict(zip(IDs, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(dictionary.values(), dictionary.keys(), columns = ['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.rename('Id', inplace = True)\n",
    "df = df.reset_index()\n",
    "df.to_csv('sample.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
